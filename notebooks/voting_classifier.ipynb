{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d513290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             confusion_matrix, average_precision_score, precision_recall_curve)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ea6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CONFIG ─────────────────────────────────────────────────────\n",
    "PROJECT_ROOT = '../'\n",
    "DATA_RAW = PROJECT_ROOT+'data/raw/'\n",
    "STATIONS = ['D08A071','D08A084','D08A115']\n",
    "ROLL_WINDOWS = [3,6,12]\n",
    "LAG_HRS = range(1,13)\n",
    "API_WINDOW = 24*7\n",
    "PERCENTILE = 0.92\n",
    "SEED = 42\n",
    "TEST_FRAC = 0.30   # 70/30 split\n",
    "MY_THR = {'D08A071':0.5, 'D08A084':0.5, 'D08A115':0.95}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a45779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_station(code):\n",
    "    csv = DATA_RAW  + code + '.csv'\n",
    "    df = pd.read_csv(csv)\n",
    "    df['datetime'] = pd.to_datetime(df['saatlik'])\n",
    "    df = (df.rename(columns={'yagis_toplam':'rain_mm','qdeger':'discharge_cms'})\n",
    "            .set_index('datetime').sort_index()\n",
    "            .resample('h').agg({'rain_mm':'sum','discharge_cms':'mean'}))\n",
    "    return df\n",
    "\n",
    "def build_features(df):\n",
    "    st = df.copy()\n",
    "    for w in ROLL_WINDOWS:\n",
    "        st[f'rain_sum_{w}h'] = st['rain_mm'].rolling(w,1).sum()\n",
    "    for l in LAG_HRS:\n",
    "        st[f'dis_lag_{l}h'] = st['discharge_cms'].shift(l)\n",
    "    st['dis_rate_1h'] = st['discharge_cms'].diff(1)\n",
    "    st['dis_rate_3h'] = st['discharge_cms'].diff(3)\n",
    "    st['API7'] = st['rain_mm'].rolling(API_WINDOW,1).sum()\n",
    "    st.dropna(inplace=True)\n",
    "    thr = st['discharge_cms'].quantile(PERCENTILE)\n",
    "    st['flood'] = (st['discharge_cms'] > thr).astype(int)\n",
    "    return st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93caa4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=SEED, class_weight='balanced'),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=SEED),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=SEED),\n",
    "    \"Logistic Reg\": LogisticRegression(max_iter=1000, random_state=SEED, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=SEED, class_weight='balanced'),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    # \"SVM\": SVC(probability=True, random_state=SEED, class_weight='balanced'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"MLP\": MLPClassifier(max_iter=800, random_state=SEED),\n",
    "    \"LSTM\": Sequential([\n",
    "        LSTM(100, input_shape=(None, 18)),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"LSTM_ES\": Sequential([\n",
    "        LSTM(100, input_shape=(None, 18)),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED, scale_pos_weight=1),\n",
    "    \"XGB_gpu\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED, scale_pos_weight=1, device='gpu', predictor='gpu_predictor'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=SEED, class_weight='balanced', device='gpu'),\n",
    "    \"LightGBM RF\": LGBMClassifier(\n",
    "        random_state=SEED, \n",
    "        class_weight='balanced', \n",
    "        device='gpu', \n",
    "        boosting_type='rf', \n",
    "        n_estimators=1000, \n",
    "        num_leaves=31, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.8, \n",
    "        reg_alpha=0.1, \n",
    "        reg_lambda=0.1, \n",
    "        bagging_fraction=0.8, \n",
    "        bagging_freq=5, \n",
    "        min_child_samples=20, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b318382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fitted(model):\n",
    "    try:\n",
    "        check_is_fitted(model)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a8278e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined dataset – random stratified 70 / 30 split + confusion matrix\n",
    "frames = [build_features(load_station(c)) for c in STATIONS]\n",
    "combined = pd.concat(frames)\n",
    "feat_cols = [c for c in combined.columns if c.startswith(('rain_sum','dis_lag','dis_rate','API'))]\n",
    "X_comb, y_comb = combined[feat_cols], combined['flood']\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_comb, y_comb, test_size=TEST_FRAC, random_state=SEED, stratify=y_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fc2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 15 classifiers...\n",
      "Training Random Forest...\n",
      "Random Forest - Time: 9.39s, Accuracy: 0.998, \n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting - Time: 8.81s, Accuracy: 0.993, \n",
      "Training AdaBoost...\n",
      "AdaBoost - Time: 2.34s, Accuracy: 0.983, \n",
      "Training Logistic Reg...\n",
      "Logistic Reg - Time: 0.75s, Accuracy: 0.908, \n",
      "Training Decision Tree...\n",
      "Decision Tree - Time: 0.28s, Accuracy: 0.996, \n",
      "Training KNN...\n",
      "KNN - Time: 1.61s, Accuracy: 0.986, \n",
      "Training Naive Bayes...\n",
      "Naive Bayes - Time: 0.06s, Accuracy: 0.925, \n",
      "Training LDA...\n",
      "LDA - Time: 0.11s, Accuracy: 0.95, \n",
      "Training MLP...\n",
      "MLP - Time: 32.14s, Accuracy: 0.99, \n",
      "Training LSTM...\n",
      "Epoch 1/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.1247\n",
      "Epoch 2/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.0974\n",
      "Epoch 3/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0883\n",
      "Epoch 4/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0790\n",
      "Epoch 5/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0717\n",
      "Epoch 6/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0669\n",
      "Epoch 7/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0631\n",
      "Epoch 8/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0608\n",
      "Epoch 9/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0588\n",
      "Epoch 10/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0567\n",
      "Epoch 11/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0558\n",
      "Epoch 12/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0539\n",
      "Epoch 13/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0532\n",
      "Epoch 14/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0518\n",
      "Epoch 15/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0522\n",
      "Epoch 16/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0501\n",
      "Epoch 17/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0500\n",
      "Epoch 18/18\n",
      "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0496\n",
      "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "LSTM - Time: 151.01s, Accuracy: 0.983, \n",
      "Training LSTM_ES...\n",
      "Epoch 1/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1479 - val_accuracy: 0.9608 - val_loss: 0.1066\n",
      "Epoch 2/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1021 - val_accuracy: 0.9726 - val_loss: 0.0949\n",
      "Epoch 3/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0975 - val_accuracy: 0.9734 - val_loss: 0.0904\n",
      "Epoch 4/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0925 - val_accuracy: 0.9723 - val_loss: 0.0837\n",
      "Epoch 5/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.0859 - val_accuracy: 0.9720 - val_loss: 0.0805\n",
      "Epoch 6/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0783 - val_accuracy: 0.9768 - val_loss: 0.0661\n",
      "Epoch 7/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0721 - val_accuracy: 0.9755 - val_loss: 0.0655\n",
      "Epoch 8/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0678 - val_accuracy: 0.9764 - val_loss: 0.0668\n",
      "Epoch 9/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0638 - val_accuracy: 0.9795 - val_loss: 0.0555\n",
      "Epoch 10/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0623 - val_accuracy: 0.9783 - val_loss: 0.0525\n",
      "Epoch 11/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0611 - val_accuracy: 0.9798 - val_loss: 0.0571\n",
      "Epoch 12/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0579 - val_accuracy: 0.9802 - val_loss: 0.0530\n",
      "Epoch 13/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0555 - val_accuracy: 0.9806 - val_loss: 0.0523\n",
      "Epoch 14/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0564 - val_accuracy: 0.9826 - val_loss: 0.0478\n",
      "Epoch 15/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0543 - val_accuracy: 0.9816 - val_loss: 0.0496\n",
      "Epoch 16/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0539 - val_accuracy: 0.9813 - val_loss: 0.0498\n",
      "Epoch 17/50\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0522 - val_accuracy: 0.9797 - val_loss: 0.0484\n",
      "\u001b[1m745/745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "LSTM_ES - Time: 72.72s, Accuracy: 0.982, \n",
      "Training XGBoost...\n",
      "[0]\tvalidation_0-logloss:0.11091\n",
      "[1]\tvalidation_0-logloss:0.08581\n",
      "[2]\tvalidation_0-logloss:0.06840\n",
      "[3]\tvalidation_0-logloss:0.05553\n",
      "[4]\tvalidation_0-logloss:0.04729\n",
      "[5]\tvalidation_0-logloss:0.03969\n",
      "[6]\tvalidation_0-logloss:0.03467\n",
      "[7]\tvalidation_0-logloss:0.03089\n",
      "[8]\tvalidation_0-logloss:0.02787\n",
      "[9]\tvalidation_0-logloss:0.02538\n",
      "[10]\tvalidation_0-logloss:0.02372\n",
      "[11]\tvalidation_0-logloss:0.02246\n",
      "[12]\tvalidation_0-logloss:0.02165\n",
      "[13]\tvalidation_0-logloss:0.02055\n",
      "[14]\tvalidation_0-logloss:0.01980\n",
      "[15]\tvalidation_0-logloss:0.01942\n",
      "[16]\tvalidation_0-logloss:0.01888\n",
      "[17]\tvalidation_0-logloss:0.01838\n",
      "[18]\tvalidation_0-logloss:0.01788\n",
      "[19]\tvalidation_0-logloss:0.01746\n",
      "[20]\tvalidation_0-logloss:0.01689\n",
      "[21]\tvalidation_0-logloss:0.01647\n",
      "[22]\tvalidation_0-logloss:0.01613\n",
      "[23]\tvalidation_0-logloss:0.01580\n",
      "[24]\tvalidation_0-logloss:0.01553\n",
      "[25]\tvalidation_0-logloss:0.01510\n",
      "[26]\tvalidation_0-logloss:0.01484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:57:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tvalidation_0-logloss:0.01448\n",
      "[28]\tvalidation_0-logloss:0.01436\n",
      "[28]\tvalidation_0-logloss:0.01436\n",
      "[29]\tvalidation_0-logloss:0.01406\n",
      "[30]\tvalidation_0-logloss:0.01383\n",
      "[29]\tvalidation_0-logloss:0.01406\n",
      "[30]\tvalidation_0-logloss:0.01383\n",
      "[31]\tvalidation_0-logloss:0.01359\n",
      "[32]\tvalidation_0-logloss:0.01347\n",
      "[31]\tvalidation_0-logloss:0.01359\n",
      "[32]\tvalidation_0-logloss:0.01347\n",
      "[33]\tvalidation_0-logloss:0.01318\n",
      "[33]\tvalidation_0-logloss:0.01318\n",
      "[34]\tvalidation_0-logloss:0.01296\n",
      "[35]\tvalidation_0-logloss:0.01277\n",
      "[36]\tvalidation_0-logloss:0.01241\n",
      "[34]\tvalidation_0-logloss:0.01296\n",
      "[35]\tvalidation_0-logloss:0.01277\n",
      "[36]\tvalidation_0-logloss:0.01241\n",
      "[37]\tvalidation_0-logloss:0.01232\n",
      "[38]\tvalidation_0-logloss:0.01224\n",
      "[39]\tvalidation_0-logloss:0.01210\n",
      "[37]\tvalidation_0-logloss:0.01232\n",
      "[38]\tvalidation_0-logloss:0.01224\n",
      "[39]\tvalidation_0-logloss:0.01210\n",
      "[40]\tvalidation_0-logloss:0.01202\n",
      "[41]\tvalidation_0-logloss:0.01191\n",
      "[42]\tvalidation_0-logloss:0.01179\n",
      "[40]\tvalidation_0-logloss:0.01202\n",
      "[41]\tvalidation_0-logloss:0.01191\n",
      "[42]\tvalidation_0-logloss:0.01179\n",
      "[43]\tvalidation_0-logloss:0.01168\n",
      "[44]\tvalidation_0-logloss:0.01166\n",
      "[43]\tvalidation_0-logloss:0.01168\n",
      "[44]\tvalidation_0-logloss:0.01166\n",
      "[45]\tvalidation_0-logloss:0.01154\n",
      "[46]\tvalidation_0-logloss:0.01145\n",
      "[47]\tvalidation_0-logloss:0.01137\n",
      "[45]\tvalidation_0-logloss:0.01154\n",
      "[46]\tvalidation_0-logloss:0.01145\n",
      "[47]\tvalidation_0-logloss:0.01137\n",
      "[48]\tvalidation_0-logloss:0.01128\n",
      "[49]\tvalidation_0-logloss:0.01120\n",
      "[48]\tvalidation_0-logloss:0.01128\n",
      "[49]\tvalidation_0-logloss:0.01120\n",
      "[50]\tvalidation_0-logloss:0.01106\n",
      "[51]\tvalidation_0-logloss:0.01101\n",
      "[50]\tvalidation_0-logloss:0.01106\n",
      "[51]\tvalidation_0-logloss:0.01101\n",
      "[52]\tvalidation_0-logloss:0.01088\n",
      "[53]\tvalidation_0-logloss:0.01076\n",
      "[54]\tvalidation_0-logloss:0.01068\n",
      "[52]\tvalidation_0-logloss:0.01088\n",
      "[53]\tvalidation_0-logloss:0.01076\n",
      "[54]\tvalidation_0-logloss:0.01068\n",
      "[55]\tvalidation_0-logloss:0.01063\n",
      "[56]\tvalidation_0-logloss:0.01057\n",
      "[55]\tvalidation_0-logloss:0.01063\n",
      "[56]\tvalidation_0-logloss:0.01057\n",
      "[57]\tvalidation_0-logloss:0.01054\n",
      "[58]\tvalidation_0-logloss:0.01050\n",
      "[59]\tvalidation_0-logloss:0.01042\n",
      "[57]\tvalidation_0-logloss:0.01054\n",
      "[58]\tvalidation_0-logloss:0.01050\n",
      "[59]\tvalidation_0-logloss:0.01042\n",
      "[60]\tvalidation_0-logloss:0.01038\n",
      "[61]\tvalidation_0-logloss:0.01026\n",
      "[62]\tvalidation_0-logloss:0.01017\n",
      "[60]\tvalidation_0-logloss:0.01038\n",
      "[61]\tvalidation_0-logloss:0.01026\n",
      "[62]\tvalidation_0-logloss:0.01017\n",
      "[63]\tvalidation_0-logloss:0.01015\n",
      "[64]\tvalidation_0-logloss:0.01014\n",
      "[65]\tvalidation_0-logloss:0.01015\n",
      "[63]\tvalidation_0-logloss:0.01015\n",
      "[64]\tvalidation_0-logloss:0.01014\n",
      "[65]\tvalidation_0-logloss:0.01015\n",
      "[66]\tvalidation_0-logloss:0.01010\n",
      "[67]\tvalidation_0-logloss:0.01009\n",
      "[66]\tvalidation_0-logloss:0.01010\n",
      "[67]\tvalidation_0-logloss:0.01009\n",
      "[68]\tvalidation_0-logloss:0.01009\n",
      "[69]\tvalidation_0-logloss:0.01007\n",
      "[68]\tvalidation_0-logloss:0.01009\n",
      "[69]\tvalidation_0-logloss:0.01007\n",
      "[70]\tvalidation_0-logloss:0.01004\n",
      "[71]\tvalidation_0-logloss:0.00997\n",
      "[70]\tvalidation_0-logloss:0.01004\n",
      "[71]\tvalidation_0-logloss:0.00997\n",
      "[72]\tvalidation_0-logloss:0.00994\n",
      "[73]\tvalidation_0-logloss:0.00988\n",
      "[74]\tvalidation_0-logloss:0.00981\n",
      "[72]\tvalidation_0-logloss:0.00994\n",
      "[73]\tvalidation_0-logloss:0.00988\n",
      "[74]\tvalidation_0-logloss:0.00981\n",
      "[75]\tvalidation_0-logloss:0.00978\n",
      "[76]\tvalidation_0-logloss:0.00982\n",
      "[77]\tvalidation_0-logloss:0.00977\n",
      "[75]\tvalidation_0-logloss:0.00978\n",
      "[76]\tvalidation_0-logloss:0.00982\n",
      "[77]\tvalidation_0-logloss:0.00977\n",
      "[78]\tvalidation_0-logloss:0.00977\n",
      "[79]\tvalidation_0-logloss:0.00975\n",
      "[80]\tvalidation_0-logloss:0.00970\n",
      "[78]\tvalidation_0-logloss:0.00977\n",
      "[79]\tvalidation_0-logloss:0.00975\n",
      "[80]\tvalidation_0-logloss:0.00970\n",
      "[81]\tvalidation_0-logloss:0.00969\n",
      "[82]\tvalidation_0-logloss:0.00967\n",
      "[81]\tvalidation_0-logloss:0.00969\n",
      "[82]\tvalidation_0-logloss:0.00967\n",
      "[83]\tvalidation_0-logloss:0.00963\n",
      "[84]\tvalidation_0-logloss:0.00964\n",
      "[83]\tvalidation_0-logloss:0.00963\n",
      "[84]\tvalidation_0-logloss:0.00964\n",
      "[85]\tvalidation_0-logloss:0.00964\n",
      "[86]\tvalidation_0-logloss:0.00963\n",
      "[87]\tvalidation_0-logloss:0.00960\n",
      "[85]\tvalidation_0-logloss:0.00964\n",
      "[86]\tvalidation_0-logloss:0.00963\n",
      "[87]\tvalidation_0-logloss:0.00960\n",
      "[88]\tvalidation_0-logloss:0.00956\n",
      "[89]\tvalidation_0-logloss:0.00953\n",
      "[88]\tvalidation_0-logloss:0.00956\n",
      "[89]\tvalidation_0-logloss:0.00953\n",
      "[90]\tvalidation_0-logloss:0.00951\n",
      "[91]\tvalidation_0-logloss:0.00950\n",
      "[90]\tvalidation_0-logloss:0.00951\n",
      "[91]\tvalidation_0-logloss:0.00950\n",
      "[92]\tvalidation_0-logloss:0.00950\n",
      "[93]\tvalidation_0-logloss:0.00941\n",
      "[92]\tvalidation_0-logloss:0.00950\n",
      "[93]\tvalidation_0-logloss:0.00941\n",
      "[94]\tvalidation_0-logloss:0.00933\n",
      "[95]\tvalidation_0-logloss:0.00931\n",
      "[94]\tvalidation_0-logloss:0.00933\n",
      "[95]\tvalidation_0-logloss:0.00931\n",
      "[96]\tvalidation_0-logloss:0.00928\n",
      "[97]\tvalidation_0-logloss:0.00928\n",
      "[98]\tvalidation_0-logloss:0.00926\n",
      "[96]\tvalidation_0-logloss:0.00928\n",
      "[97]\tvalidation_0-logloss:0.00928\n",
      "[98]\tvalidation_0-logloss:0.00926\n",
      "[99]\tvalidation_0-logloss:0.00925\n",
      "[99]\tvalidation_0-logloss:0.00925\n",
      "XGBoost - Time: 0.98s, Accuracy: 0.997, \n",
      "Training XGB_gpu...\n",
      "XGBoost - Time: 0.98s, Accuracy: 0.997, \n",
      "Training XGB_gpu...\n",
      "[0]\tvalidation_0-logloss:0.11092\n",
      "[0]\tvalidation_0-logloss:0.11092\n",
      "[1]\tvalidation_0-logloss:0.08582\n",
      "[1]\tvalidation_0-logloss:0.08582\n",
      "[2]\tvalidation_0-logloss:0.06840\n",
      "[2]\tvalidation_0-logloss:0.06840\n",
      "[3]\tvalidation_0-logloss:0.05562\n",
      "[3]\tvalidation_0-logloss:0.05562\n",
      "[4]\tvalidation_0-logloss:0.04749\n",
      "[4]\tvalidation_0-logloss:0.04749\n",
      "[5]\tvalidation_0-logloss:0.03967\n",
      "[5]\tvalidation_0-logloss:0.03967\n",
      "[6]\tvalidation_0-logloss:0.03463\n",
      "[6]\tvalidation_0-logloss:0.03463\n",
      "[7]\tvalidation_0-logloss:0.03090\n",
      "[7]\tvalidation_0-logloss:0.03090\n",
      "[8]\tvalidation_0-logloss:0.02825\n",
      "[8]\tvalidation_0-logloss:0.02825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:58:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\tvalidation_0-logloss:0.02574\n",
      "[10]\tvalidation_0-logloss:0.02388\n",
      "[10]\tvalidation_0-logloss:0.02388\n",
      "[11]\tvalidation_0-logloss:0.02245\n",
      "[12]\tvalidation_0-logloss:0.02117\n",
      "[11]\tvalidation_0-logloss:0.02245\n",
      "[12]\tvalidation_0-logloss:0.02117\n",
      "[13]\tvalidation_0-logloss:0.02008\n",
      "[13]\tvalidation_0-logloss:0.02008\n",
      "[14]\tvalidation_0-logloss:0.01895\n",
      "[14]\tvalidation_0-logloss:0.01895\n",
      "[15]\tvalidation_0-logloss:0.01853\n",
      "[16]\tvalidation_0-logloss:0.01813\n",
      "[15]\tvalidation_0-logloss:0.01853\n",
      "[16]\tvalidation_0-logloss:0.01813\n",
      "[17]\tvalidation_0-logloss:0.01771\n",
      "[18]\tvalidation_0-logloss:0.01712\n",
      "[19]\tvalidation_0-logloss:0.01674\n",
      "[17]\tvalidation_0-logloss:0.01771\n",
      "[18]\tvalidation_0-logloss:0.01712\n",
      "[19]\tvalidation_0-logloss:0.01674\n",
      "[20]\tvalidation_0-logloss:0.01652\n",
      "[21]\tvalidation_0-logloss:0.01625\n",
      "[22]\tvalidation_0-logloss:0.01572\n",
      "[20]\tvalidation_0-logloss:0.01652\n",
      "[21]\tvalidation_0-logloss:0.01625\n",
      "[22]\tvalidation_0-logloss:0.01572\n",
      "[23]\tvalidation_0-logloss:0.01542\n",
      "[24]\tvalidation_0-logloss:0.01511\n",
      "[25]\tvalidation_0-logloss:0.01485\n",
      "[23]\tvalidation_0-logloss:0.01542\n",
      "[24]\tvalidation_0-logloss:0.01511\n",
      "[25]\tvalidation_0-logloss:0.01485\n",
      "[26]\tvalidation_0-logloss:0.01460\n",
      "[27]\tvalidation_0-logloss:0.01444\n",
      "[28]\tvalidation_0-logloss:0.01419\n",
      "[26]\tvalidation_0-logloss:0.01460\n",
      "[27]\tvalidation_0-logloss:0.01444\n",
      "[28]\tvalidation_0-logloss:0.01419\n",
      "[29]\tvalidation_0-logloss:0.01405\n",
      "[30]\tvalidation_0-logloss:0.01382\n",
      "[31]\tvalidation_0-logloss:0.01366\n",
      "[29]\tvalidation_0-logloss:0.01405\n",
      "[30]\tvalidation_0-logloss:0.01382\n",
      "[31]\tvalidation_0-logloss:0.01366\n",
      "[32]\tvalidation_0-logloss:0.01350\n",
      "[33]\tvalidation_0-logloss:0.01337\n",
      "[34]\tvalidation_0-logloss:0.01331\n",
      "[32]\tvalidation_0-logloss:0.01350\n",
      "[33]\tvalidation_0-logloss:0.01337\n",
      "[34]\tvalidation_0-logloss:0.01331\n",
      "[35]\tvalidation_0-logloss:0.01307\n",
      "[36]\tvalidation_0-logloss:0.01286\n",
      "[37]\tvalidation_0-logloss:0.01272\n",
      "[35]\tvalidation_0-logloss:0.01307\n",
      "[36]\tvalidation_0-logloss:0.01286\n",
      "[37]\tvalidation_0-logloss:0.01272\n",
      "[38]\tvalidation_0-logloss:0.01255\n",
      "[39]\tvalidation_0-logloss:0.01241\n",
      "[40]\tvalidation_0-logloss:0.01235\n",
      "[38]\tvalidation_0-logloss:0.01255\n",
      "[39]\tvalidation_0-logloss:0.01241\n",
      "[40]\tvalidation_0-logloss:0.01235\n",
      "[41]\tvalidation_0-logloss:0.01220\n",
      "[42]\tvalidation_0-logloss:0.01211\n",
      "[43]\tvalidation_0-logloss:0.01195\n",
      "[41]\tvalidation_0-logloss:0.01220\n",
      "[42]\tvalidation_0-logloss:0.01211\n",
      "[43]\tvalidation_0-logloss:0.01195\n",
      "[44]\tvalidation_0-logloss:0.01194\n",
      "[45]\tvalidation_0-logloss:0.01182\n",
      "[46]\tvalidation_0-logloss:0.01171\n",
      "[44]\tvalidation_0-logloss:0.01194\n",
      "[45]\tvalidation_0-logloss:0.01182\n",
      "[46]\tvalidation_0-logloss:0.01171\n",
      "[47]\tvalidation_0-logloss:0.01159\n",
      "[48]\tvalidation_0-logloss:0.01142\n",
      "[49]\tvalidation_0-logloss:0.01136\n",
      "[47]\tvalidation_0-logloss:0.01159\n",
      "[48]\tvalidation_0-logloss:0.01142\n",
      "[49]\tvalidation_0-logloss:0.01136\n",
      "[50]\tvalidation_0-logloss:0.01130\n",
      "[51]\tvalidation_0-logloss:0.01121\n",
      "[50]\tvalidation_0-logloss:0.01130\n",
      "[51]\tvalidation_0-logloss:0.01121\n",
      "[52]\tvalidation_0-logloss:0.01120\n",
      "[53]\tvalidation_0-logloss:0.01104\n",
      "[52]\tvalidation_0-logloss:0.01120\n",
      "[53]\tvalidation_0-logloss:0.01104\n",
      "[54]\tvalidation_0-logloss:0.01099\n",
      "[55]\tvalidation_0-logloss:0.01100\n",
      "[54]\tvalidation_0-logloss:0.01099\n",
      "[55]\tvalidation_0-logloss:0.01100\n",
      "[56]\tvalidation_0-logloss:0.01095\n",
      "[57]\tvalidation_0-logloss:0.01086\n",
      "[58]\tvalidation_0-logloss:0.01081\n",
      "[56]\tvalidation_0-logloss:0.01095\n",
      "[57]\tvalidation_0-logloss:0.01086\n",
      "[58]\tvalidation_0-logloss:0.01081\n",
      "[59]\tvalidation_0-logloss:0.01076\n",
      "[60]\tvalidation_0-logloss:0.01070\n",
      "[61]\tvalidation_0-logloss:0.01070\n",
      "[59]\tvalidation_0-logloss:0.01076\n",
      "[60]\tvalidation_0-logloss:0.01070\n",
      "[61]\tvalidation_0-logloss:0.01070\n",
      "[62]\tvalidation_0-logloss:0.01057\n",
      "[63]\tvalidation_0-logloss:0.01051\n",
      "[64]\tvalidation_0-logloss:0.01047\n",
      "[62]\tvalidation_0-logloss:0.01057\n",
      "[63]\tvalidation_0-logloss:0.01051\n",
      "[64]\tvalidation_0-logloss:0.01047\n",
      "[65]\tvalidation_0-logloss:0.01049\n",
      "[66]\tvalidation_0-logloss:0.01045\n",
      "[67]\tvalidation_0-logloss:0.01046\n",
      "[65]\tvalidation_0-logloss:0.01049\n",
      "[66]\tvalidation_0-logloss:0.01045\n",
      "[67]\tvalidation_0-logloss:0.01046\n",
      "[68]\tvalidation_0-logloss:0.01046\n",
      "[69]\tvalidation_0-logloss:0.01047\n",
      "[70]\tvalidation_0-logloss:0.01044\n",
      "[68]\tvalidation_0-logloss:0.01046\n",
      "[69]\tvalidation_0-logloss:0.01047\n",
      "[70]\tvalidation_0-logloss:0.01044\n",
      "[71]\tvalidation_0-logloss:0.01043\n",
      "[72]\tvalidation_0-logloss:0.01033\n",
      "[73]\tvalidation_0-logloss:0.01031\n",
      "[71]\tvalidation_0-logloss:0.01043\n",
      "[72]\tvalidation_0-logloss:0.01033\n",
      "[73]\tvalidation_0-logloss:0.01031\n",
      "[74]\tvalidation_0-logloss:0.01024\n",
      "[75]\tvalidation_0-logloss:0.01024\n",
      "[74]\tvalidation_0-logloss:0.01024\n",
      "[75]\tvalidation_0-logloss:0.01024\n",
      "[76]\tvalidation_0-logloss:0.01022\n",
      "[77]\tvalidation_0-logloss:0.01019\n",
      "[78]\tvalidation_0-logloss:0.01021\n",
      "[76]\tvalidation_0-logloss:0.01022\n",
      "[77]\tvalidation_0-logloss:0.01019\n",
      "[78]\tvalidation_0-logloss:0.01021\n",
      "[79]\tvalidation_0-logloss:0.01017\n",
      "[80]\tvalidation_0-logloss:0.01011\n",
      "[81]\tvalidation_0-logloss:0.01007\n",
      "[79]\tvalidation_0-logloss:0.01017\n",
      "[80]\tvalidation_0-logloss:0.01011\n",
      "[81]\tvalidation_0-logloss:0.01007\n",
      "[82]\tvalidation_0-logloss:0.01000\n",
      "[83]\tvalidation_0-logloss:0.00997\n",
      "[84]\tvalidation_0-logloss:0.00994\n",
      "[85]\tvalidation_0-logloss:0.00990\n",
      "[82]\tvalidation_0-logloss:0.01000\n",
      "[83]\tvalidation_0-logloss:0.00997\n",
      "[84]\tvalidation_0-logloss:0.00994\n",
      "[85]\tvalidation_0-logloss:0.00990\n",
      "[86]\tvalidation_0-logloss:0.00988\n",
      "[87]\tvalidation_0-logloss:0.00986\n",
      "[88]\tvalidation_0-logloss:0.00990\n",
      "[86]\tvalidation_0-logloss:0.00988\n",
      "[87]\tvalidation_0-logloss:0.00986\n",
      "[88]\tvalidation_0-logloss:0.00990\n",
      "[89]\tvalidation_0-logloss:0.00993\n",
      "[90]\tvalidation_0-logloss:0.00989\n",
      "[91]\tvalidation_0-logloss:0.00980\n",
      "[89]\tvalidation_0-logloss:0.00993\n",
      "[90]\tvalidation_0-logloss:0.00989\n",
      "[91]\tvalidation_0-logloss:0.00980\n",
      "[92]\tvalidation_0-logloss:0.00979\n",
      "[93]\tvalidation_0-logloss:0.00981\n",
      "[94]\tvalidation_0-logloss:0.00982\n",
      "[92]\tvalidation_0-logloss:0.00979\n",
      "[93]\tvalidation_0-logloss:0.00981\n",
      "[94]\tvalidation_0-logloss:0.00982\n",
      "[95]\tvalidation_0-logloss:0.00981\n",
      "[96]\tvalidation_0-logloss:0.00980\n",
      "[95]\tvalidation_0-logloss:0.00981\n",
      "[96]\tvalidation_0-logloss:0.00980\n",
      "[97]\tvalidation_0-logloss:0.00978\n",
      "[98]\tvalidation_0-logloss:0.00981\n",
      "[99]\tvalidation_0-logloss:0.00983\n",
      "[97]\tvalidation_0-logloss:0.00978\n",
      "[98]\tvalidation_0-logloss:0.00981\n",
      "[99]\tvalidation_0-logloss:0.00983\n",
      "XGB_gpu - Time: 0.89s, Accuracy: 0.997, \n",
      "Training LightGBM...\n",
      "XGB_gpu - Time: 0.89s, Accuracy: 0.997, \n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 4252, number of negative: 51369\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 4590\n",
      "[LightGBM] [Info] Number of data points in the train set: 55621, number of used features: 18\n",
      "[LightGBM] [Info] Number of positive: 4252, number of negative: 51369\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 4590\n",
      "[LightGBM] [Info] Number of data points in the train set: 55621, number of used features: 18\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1650, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.85 MB) transferred to GPU in 0.002692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1650, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.85 MB) transferred to GPU in 0.002692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "LightGBM - Time: 1.01s, Accuracy: 0.997, \n",
      "Training LightGBM RF...\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 4252, number of negative: 51369\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 4590\n",
      "[LightGBM] [Info] Number of data points in the train set: 55621, number of used features: 18\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1650, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.85 MB) transferred to GPU in 0.002814 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002501 secs. 1 sparse feature groups\n",
      "LightGBM - Time: 1.01s, Accuracy: 0.997, \n",
      "Training LightGBM RF...\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 4252, number of negative: 51369\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 4590\n",
      "[LightGBM] [Info] Number of data points in the train set: 55621, number of used features: 18\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1650, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.85 MB) transferred to GPU in 0.002814 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.005952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.005952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002085 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002075 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002085 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002075 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002060 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.005356 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002060 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.005356 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002284 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002284 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002302 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002072 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002302 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002072 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002264 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002222 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002264 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002222 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002168 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002168 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002289 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002384 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002289 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002384 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003086 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003086 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.004176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.004176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002017 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002017 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002207 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002135 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002843 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002207 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002135 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002843 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.001942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002055 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002055 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002370 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002109 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002167 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002370 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002109 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002167 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002300 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002300 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002201 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002201 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002272 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002272 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002124 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002321 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002124 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002321 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002181 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002015 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002181 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002015 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.002378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003442 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.68 MB) transferred to GPU in 0.003242 secs. 1 sparse feature groups\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "print(f\"Training {len(classifiers)} classifiers...\")\n",
    "for name, clf in classifiers.items():\n",
    "   \n",
    "    start_time = time.time()\n",
    "    print(f\"Training {name}...\")\n",
    "    if not is_fitted(clf):\n",
    "        if name in [\"LSTM\", \"LSTM_ES\"]:\n",
    "            # Reshape for LSTM input\n",
    "            clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            X_tr_lstm = X_tr.values.reshape((X_tr.shape[0], 1, X_tr.shape[1]))\n",
    "            X_te_lstm = X_te.values.reshape((X_te.shape[0], 1, X_te.shape[1]))\n",
    "            if name == \"LSTM_ES\":\n",
    "                # Use EarlyStopping for LSTM with validation split and early stopping\n",
    "                early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "                clf.fit(X_tr_lstm, y_tr, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "            else:\n",
    "                # Fit LSTM without validation split or early stopping\n",
    "                clf.fit(X_tr_lstm, y_tr, epochs=18, batch_size=16)\n",
    "            prob = clf.predict(X_te_lstm).flatten()\n",
    "        else:\n",
    "            if name in [\"XGBoost\", \"XGB_gpu\"]:\n",
    "                # Fit XGBoost and LightGBM classifiers\n",
    "                clf.fit(X_tr, y_tr, eval_set=[(X_te, y_te)])\n",
    "                prob = clf.predict_proba(X_te)[:, 1]\n",
    "            else:\n",
    "                if name in [\"LightGBM\", \"LightGBM RF\"]:\n",
    "                    # Fit LightGBM classifiers\n",
    "                    clf.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], eval_metric='binary_logloss')\n",
    "                    prob = clf.predict_proba(X_te)[:, 1]\n",
    "                else:\n",
    "                    # Fit other classifiers    \n",
    "                    clf.fit(X_tr, y_tr)\n",
    "                    prob  = clf.predict_proba(X_te)[:, 1] if hasattr(clf, \"predict_proba\") else clf.decision_function(X_te)\n",
    "    else:\n",
    "        print(f\"{name} is already fitted, skipping training.\")\n",
    "        if name in [\"LSTM\", \"LSTM_ES\"]:\n",
    "            X_te_lstm = X_te.values.reshape((X_te.shape[0], 1, X_te.shape[1]))\n",
    "            prob = clf.predict(X_te_lstm).flatten()\n",
    "        else:\n",
    "            prob = clf.predict_proba(X_te)[:, 1] if hasattr(clf, \"predict_proba\") else clf.decision_function(X_te)\n",
    "    pred  = (prob > 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    rows.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': round(accuracy_score(y_te, pred), 3),\n",
    "        'Precision': round(precision_score(y_te, pred), 3),\n",
    "        'Recall': round(recall_score(y_te, pred), 3),\n",
    "        'PR-AUC': round(average_precision_score(y_te, prob), 3),\n",
    "        'ConfMatrix': f\"[[{tn} {fp}] [{fn} {tp}]]\"\n",
    "    })\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"{name} - Time: {elapsed_time:.2f}s, Accuracy: {rows[-1]['Accuracy']}, \")\n",
    "\n",
    "(pd.DataFrame(rows)\n",
    "   .set_index('Model')\n",
    "   .sort_values('PR-AUC', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Seleciona todos os classificadores scikit-learn (exclui LSTM e LSTM_ES)\n",
    "ensemble_names = [k for k in classifiers.keys() if k not in [\"LSTM\", \"LSTM_ES\"]]\n",
    "voting_estimators = [(name, classifiers[name]) for name in ensemble_names]\n",
    "\n",
    "voting = VotingClassifier(estimators=voting_estimators, voting='soft')\n",
    "\n",
    "# Treinamento\n",
    "voting.fit(X_tr, y_tr)\n",
    "\n",
    "# Predição e avaliação\n",
    "prob = voting.predict_proba(X_te)[:, 1]\n",
    "pred = (prob > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, average_precision_score, confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, pred, labels=[0, 1]).ravel()\n",
    "print(f\"VotingClassifier - Accuracy: {accuracy_score(y_te, pred):.3f}, Precision: {precision_score(y_te, pred):.3f}, Recall: {recall_score(y_te, pred):.3f}, PR-AUC: {average_precision_score(y_te, prob):.3f}\")\n",
    "print(f\"ConfMatrix: [[{tn} {fp}] [{fn} {tp}]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e349ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from IPython.display import display\\n\\nfor code in STATIONS:\\n    df = build_features(load_station(code))\\n    X, y = df[feat_cols], df[\\'flood\\']\\n    X_tr, X_te, y_tr, y_te = train_test_split(\\n        X, y, test_size=TEST_FRAC, random_state=SEED, stratify=y)\\n\\n    print(f\"### {code}\")\\n    tbl = []\\n\\n    plt.figure(figsize=(5, 4))\\n    for name, clf in classifiers.items():\\n        if name in [\"LSTM\", \"LSTM_ES\"]:\\n            # Reshape for LSTM input\\n            X_tr_lstm = X_tr.values.reshape((X_tr.shape[0], 1, X_tr.shape[1]))\\n            X_te_lstm = X_te.values.reshape((X_te.shape[0], 1, X_te.shape[1]))\\n            if name == \"LSTM_ES\":\\n                # Use EarlyStopping for LSTM with validation split\\n                early_stop = EarlyStopping(monitor=\\'val_loss\\', patience=3, restore_best_weights=True)\\n                clf.fit(X_tr_lstm, y_tr, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stop])\\n            else:\\n                # Fit LSTM without validation split\\n                clf.fit(X_tr_lstm, y_tr, epochs=18, batch_size=16)\\n            prob = clf.predict(X_te_lstm).flatten()\\n        else:\\n            if name in [\"XGBoost\", \"XGB_gpu\", \"LightGBM\", \"LightGBM RF\"]:\\n                # Fit XGBoost and LightGBM classifiers\\n                clf.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False)\\n                prob = clf.predict_proba(X_te)[:, 1]\\n            else:\\n                # Fit other classifiers    \\n                clf.fit(X_tr, y_tr)\\n                prob  = clf.predict_proba(X_te)[:, 1] if hasattr(clf, \"predict_proba\") else clf.decision_function(X_te)\\n        pr_auc = average_precision_score(y_te, prob)\\n        prec_curve, rec_curve, _ = precision_recall_curve(y_te, prob)\\n        plt.plot(rec_curve, prec_curve, lw=1, label=f\"{name} (AP={pr_auc:.2f})\")\\n\\n        thr  = MY_THR[code]\\n        pred = (prob > thr).astype(int)\\n        tn, fp, fn, tp = confusion_matrix(y_te, pred, labels=[0, 1]).ravel()\\n\\n        tbl.append({\\n            \\'Model\\': name,\\n            \\'Precision\\': round(precision_score(y_te, pred, zero_division=1), 3),\\n            \\'Recall\\': round(recall_score(y_te, pred), 3),\\n            \\'PR-AUC\\': round(pr_auc, 3),\\n            \\'ConfMatrix\\': f\"[[{tn} {fp}] [{fn} {tp}]]\"\\n        })\\n\\n    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\\n    plt.title(f\"PR curve – {code}\")\\n    plt.legend(fontsize=\"xx-small\")\\n    plt.show()\\n\\n    display(pd.DataFrame(tbl).set_index(\"Model\").sort_values(\"PR-AUC\", ascending=False)) '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from IPython.display import display\n",
    "\n",
    "for code in STATIONS:\n",
    "    df = build_features(load_station(code))\n",
    "    X, y = df[feat_cols], df['flood']\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=TEST_FRAC, random_state=SEED, stratify=y)\n",
    "\n",
    "    print(f\"### {code}\")\n",
    "    tbl = []\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    for name, clf in classifiers.items():\n",
    "        if name in [\"LSTM\", \"LSTM_ES\"]:\n",
    "            # Reshape for LSTM input\n",
    "            X_tr_lstm = X_tr.values.reshape((X_tr.shape[0], 1, X_tr.shape[1]))\n",
    "            X_te_lstm = X_te.values.reshape((X_te.shape[0], 1, X_te.shape[1]))\n",
    "            if name == \"LSTM_ES\":\n",
    "                # Use EarlyStopping for LSTM with validation split\n",
    "                early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "                clf.fit(X_tr_lstm, y_tr, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "            else:\n",
    "                # Fit LSTM without validation split\n",
    "                clf.fit(X_tr_lstm, y_tr, epochs=18, batch_size=16)\n",
    "            prob = clf.predict(X_te_lstm).flatten()\n",
    "        else:\n",
    "            if name in [\"XGBoost\", \"XGB_gpu\", \"LightGBM\", \"LightGBM RF\"]:\n",
    "                # Fit XGBoost and LightGBM classifiers\n",
    "                clf.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False)\n",
    "                prob = clf.predict_proba(X_te)[:, 1]\n",
    "            else:\n",
    "                # Fit other classifiers    \n",
    "                clf.fit(X_tr, y_tr)\n",
    "                prob  = clf.predict_proba(X_te)[:, 1] if hasattr(clf, \"predict_proba\") else clf.decision_function(X_te)\n",
    "        pr_auc = average_precision_score(y_te, prob)\n",
    "        prec_curve, rec_curve, _ = precision_recall_curve(y_te, prob)\n",
    "        plt.plot(rec_curve, prec_curve, lw=1, label=f\"{name} (AP={pr_auc:.2f})\")\n",
    "\n",
    "        thr  = MY_THR[code]\n",
    "        pred = (prob > thr).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, pred, labels=[0, 1]).ravel()\n",
    "\n",
    "        tbl.append({\n",
    "            'Model': name,\n",
    "            'Precision': round(precision_score(y_te, pred, zero_division=1), 3),\n",
    "            'Recall': round(recall_score(y_te, pred), 3),\n",
    "            'PR-AUC': round(pr_auc, 3),\n",
    "            'ConfMatrix': f\"[[{tn} {fp}] [{fn} {tp}]]\"\n",
    "        })\n",
    "\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"PR curve – {code}\")\n",
    "    plt.legend(fontsize=\"xx-small\")\n",
    "    plt.show()\n",
    "\n",
    "    display(pd.DataFrame(tbl).set_index(\"Model\").sort_values(\"PR-AUC\", ascending=False)) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
